[{"authors":["admin"],"categories":null,"content":"I am a Psychology PhD Student at the University of Oregon. My research uses data-driven predictive modeling to explore personality and mental health in the context of online social networks. I am also pursuing a Data Science specialization focused on data visualization, functional programming, and machine learning.\nI am excited to apply my analytical skills to collaborative projects focused on real-world problems and societal benefit. When I\u0026rsquo;m not coding, I love baking and exploring the Pacific Northwest.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"I am a Psychology PhD Student at the University of Oregon. My research uses data-driven predictive modeling to explore personality and mental health in the context of online social networks. I am also pursuing a Data Science specialization focused on data visualization, functional programming, and machine learning.","tags":null,"title":"","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":" Intro Tidyverse’s newest release has recently come together to form a cohesive suite of packages for modeling and machine learning, called {tidymodels}. The successor to Max Kuhn’s {caret} package, {tidymodels} allows for a tidy approach to your data from start to finish. We’re going to walk through the basics for getting off the ground with {tidymodels} and demonstrate its application to three different tree-based methods for predicting student test scores. For further information about the package, you can visit https://www.tidymodels.org/.\n Setup Load both the {tidyverse} and {tidymodels} packages into your environment. We’ll also load in the {skimr} package to help us with some descriptives for our data and a host of other packages that will be required to run our machine learning models.\nlibrary(tidymodels) library(tidyverse) # manipulating data library(skimr) # data visualization library(baguette) # bagged trees library(future) # parallel processing \u0026amp; decrease computation time library(xgboost) # boosted trees  Import the data We’re using simulated data which approximates reading and math scores for ~189,000 3rd-8th grade students in Oregon public schools see this Kaggle page for details. For the purpose of demonstration, we’ll be sampling 1% of the data with sample_frac() to keep computer processing time manageable. All school IDs in the data are real, so we can use that information to link the data with other sources. Specifically, we’re also going to pull in some data on student enrollment in free and reduced lunch from the National Center for Education Statistics and some ethnicity data from the Oregon Department of Education.\nset.seed(100) # import data and perform initial cleaning # initial cleaning steps include: # *recode NA\u0026#39;s for lang_cd and ayp_lep to more meaningful values # *remove vars with entirely missing data # Note: the data is called \u0026#39;train.csv\u0026#39;, but we will actually further split this into its own training and testing data dat \u0026lt;- read_csv(here::here(\u0026quot;static\u0026quot;, \u0026quot;data\u0026quot;, \u0026quot;train.csv\u0026quot;)) %\u0026gt;% select(-classification) %\u0026gt;% # remove this variable because it\u0026#39;s redundant with `score` mutate(lang_cd = ifelse(is.na(lang_cd), \u0026quot;E\u0026quot;, lang_cd), ayp_lep = ifelse(is.na(ayp_lep), \u0026quot;G\u0026quot;, ayp_lep)) %\u0026gt;% sample_frac(.01) %\u0026gt;% # sample 1% of the data to reduce run time janitor::remove_empty(c(\u0026quot;rows\u0026quot;, \u0026quot;cols\u0026quot;)) %\u0026gt;% drop_na() %\u0026gt;% select_if(~length(unique(.x)) \u0026gt; 1) # import fall membership report ethcnicity data and do some basic cleaning and renaming sheets \u0026lt;- readxl::excel_sheets(here::here(\u0026quot;static\u0026quot;, \u0026quot;data\u0026quot;, \u0026quot;fallmembershipreport_20192020.xlsx\u0026quot;)) ode_schools \u0026lt;- readxl::read_xlsx(here::here(\u0026quot;static\u0026quot;, \u0026quot;data\u0026quot;, \u0026quot;fallmembershipreport_20192020.xlsx\u0026quot;), sheet = sheets[4]) ethnicities \u0026lt;- ode_schools %\u0026gt;% select(attnd_schl_inst_id = `Attending School ID`, attnd_dist_inst_id = `Attending District Institution ID`, sch_name = `School Name`, contains(\u0026quot;%\u0026quot;)) %\u0026gt;% janitor::clean_names() names(ethnicities) \u0026lt;- gsub(\u0026quot;x2019_20_percent\u0026quot;, \u0026quot;p\u0026quot;, names(ethnicities)) # join ethnicity data with original dataset dat \u0026lt;- left_join(dat, ethnicities) # import and tidy free and reduced lunch data frl \u0026lt;- rio::import(\u0026quot;https://nces.ed.gov/ccd/Data/zip/ccd_sch_033_1718_l_1a_083118.zip\u0026quot;, setclass = \u0026quot;tbl_df\u0026quot;) %\u0026gt;% janitor::clean_names() %\u0026gt;% filter(st == \u0026quot;OR\u0026quot;) %\u0026gt;% select(ncessch, lunch_program, student_count) %\u0026gt;% mutate(student_count = replace_na(student_count, 0)) %\u0026gt;% pivot_wider(names_from = lunch_program, values_from = student_count) %\u0026gt;% janitor::clean_names() %\u0026gt;% mutate(ncessch = as.double(ncessch)) # import student counts for each school across grades stu_counts \u0026lt;- rio::import(\u0026quot;https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv\u0026quot;, setclass = \u0026quot;tbl_df\u0026quot;) %\u0026gt;% filter(state == \u0026quot;OR\u0026quot; \u0026amp; year == 1718) %\u0026gt;% count(ncessch, wt = n) %\u0026gt;% mutate(ncessch = as.double(ncessch)) # join frl and stu_counts data frl \u0026lt;- left_join(frl, stu_counts) # add frl data to train data dat \u0026lt;- left_join(dat, frl) After loading in our three datasets, we’ll join them together to make one cohesive data set to use for modeling. After joining, the data contains both student-level variables (e.g. gender, ethnicity, enrollment in special education/talented and gifted programs, etc.) and district-level variables (e.g. school longitude and latitude, proportion of students who qualify for free and reduced-price lunch, etc.), all of which will be included for each 3 of our {tidymodels} tree-based examples.\nFor a more complete description of the variables, you can download the data dictionary here.\n Explore the data We’ll use the skim() function from {skimr} to take a closer look at our variables. Many numeric predictors are clearly non-normal (see histograms below), but this is no problem as tree-based methods are robust to non-normality.\ndat %\u0026gt;% select(-contains(\u0026quot;id\u0026quot;), -ncessch, -missing, -not_applicable) %\u0026gt;% # remove ID and irrelevant variables mutate(tst_dt = lubridate::as_date(lubridate::mdy_hms(tst_dt))) %\u0026gt;% # covert test date to date modify_if(is.character, as.factor) %\u0026gt;% # convert character vars to factors skim() %\u0026gt;% select(-starts_with(\u0026quot;numeric.p\u0026quot;)) # remove quartiles  Table 1: Data summary  Name Piped data  Number of rows 1857  Number of columns 41  _______________________   Column type frequency:   Date 1  factor 25  numeric 15  ________________________   Group variables None    Variable type: Date\n  skim_variable n_missing complete_rate min max median n_unique    tst_dt 0 1 2018-03-16 2018-06-07 2018-05-18 47    Variable type: factor\n  skim_variable n_missing complete_rate ordered n_unique top_counts    gndr 0 1 FALSE 2 M: 939, F: 918  ethnic_cd 0 1 FALSE 7 W: 1151, H: 458, M: 100, A: 79  tst_bnch 0 1 FALSE 6 G6: 343, 1B: 330, G4: 304, G7: 304  migrant_ed_fg 0 1 FALSE 2 N: 1793, Y: 64  ind_ed_fg 0 1 FALSE 2 N: 1842, Y: 15  sp_ed_fg 0 1 FALSE 2 N: 1614, Y: 243  tag_ed_fg 0 1 FALSE 2 N: 1759, Y: 98  econ_dsvntg 0 1 FALSE 2 Y: 1100, N: 757  ayp_lep 0 1 FALSE 10 G: 1471, F: 164, Y: 72, E: 58  stay_in_dist 0 1 FALSE 2 Y: 1811, N: 46  stay_in_schl 0 1 FALSE 2 Y: 1803, N: 54  dist_sped 0 1 FALSE 2 N: 1846, Y: 11  trgt_assist_fg 0 1 FALSE 3 N: 1773, Y: 83, y: 1  ayp_schl_partic 0 1 FALSE 2 Y: 1846, N: 11  ayp_dist_prfrm 0 1 FALSE 2 Y: 1803, N: 54  ayp_schl_prfrm 0 1 FALSE 2 Y: 1785, N: 72  rc_schl_partic 0 1 FALSE 2 Y: 1846, N: 11  rc_dist_prfrm 0 1 FALSE 2 Y: 1803, N: 54  rc_schl_prfrm 0 1 FALSE 2 Y: 1785, N: 72  lang_cd 0 1 FALSE 2 E: 1815, S: 42  tst_atmpt_fg 0 1 FALSE 2 Y: 1853, P: 4  grp_rpt_schl_partic 0 1 FALSE 2 Y: 1846, N: 11  grp_rpt_dist_prfrm 0 1 FALSE 2 Y: 1845, N: 12  grp_rpt_schl_prfrm 0 1 FALSE 2 Y: 1834, N: 23  sch_name 1 1 FALSE 699 Hig: 14, Jud: 14, Hou: 13, Fiv: 11    Variable type: numeric\n  skim_variable n_missing complete_rate mean sd hist    enrl_grd 0 1 5.44 1.69 ▇▃▅▃▃  score 0 1 2495.34 115.19 ▁▁▂▇▁  lat 0 1 44.79 0.99 ▂▁▂▅▇  lon 0 1 -122.51 1.16 ▅▇▁▁▁  p_american_indian_alaska_native 1 1 0.01 0.06 ▇▁▁▁▁  p_asian 1 1 0.04 0.07 ▇▁▁▁▁  p_native_hawaiian_pacific_islander 1 1 0.01 0.01 ▇▁▁▁▁  p_black_african_american 1 1 0.02 0.04 ▇▁▁▁▁  p_hispanic_latino 1 1 0.25 0.18 ▇▅▂▁▁  p_white 1 1 0.60 0.20 ▁▃▅▇▅  p_multiracial 1 1 0.06 0.03 ▇▆▁▁▁  free_lunch_qualified 0 1 231.23 147.55 ▇▇▃▁▁  reduced_price_lunch_qualified 0 1 39.86 24.77 ▆▇▃▁▁  no_category_codes 0 1 271.09 165.44 ▆▇▃▁▁  n 0 1 816.07 536.55 ▇▃▂▁▁    While most of our predictors are categorical, we can use {corrplot} to better visualize the relationships among the numeric variables.\ndat %\u0026gt;% select(-contains(\u0026quot;id\u0026quot;), -ncessch, -missing, -not_applicable) %\u0026gt;% select_if(is.numeric) %\u0026gt;% select(score, everything()) %\u0026gt;% cor(use = \u0026quot;pairwise.complete.obs\u0026quot;) %\u0026gt;% corrplot::corrplot()  Split data and resample The first step of our analysis is to split our data into two separate sets: a “training” set and a “testing” set. The training set is used to train a model and, if desired, to adjust (i.e., “tune”) the model’s hyperparameters before evaluating its final performance on our test data. By allowing us to test a model on a new sample, we assess “out of sample” accuracy (i.e., unseen data-—what all predictive models are interested in) and limit overfitting to the training set. We can do this efficiently with the initial_split() function. This comes from the {rsample} package, which is part of the {tidymodels} package that we already loaded. Defaults put 75% of the data in the training set and 25% in the test set, but this can be adjusted with the prop argument. Then, we’ll extract the training data from our split object and assign it a name.\nTo further prevent over-fitting, we’ll resample our data using vfold_cv(). This function outputs k-fold cross-validated versions of our training data, where k = the number of times we resample (unsure why v- is used instead of k- here). By using k = 10 data sets, we get a better estimate of the model’s out-of-sample accuracy. On top of decreasing bias from over-fitting, this is essential when tuning hyperparameters (though we plan to apply defaults and not tune here, for brevity). Though our use of 10-fold cross validation is both frequently used and effective, it should be noted that other methods (e.g., bootstrap resampling) or other k-values are sometimes used to accomplish the same goal.\nset.seed(100) # split the data split \u0026lt;- initial_split(dat) # extract the training data train \u0026lt;- training(split) # resample the data with 10-fold cross-validation (10-fold by default) cv \u0026lt;- vfold_cv(train)  Pre-processing Before we add in our data to the model, we’re going to set up an object that pre-processes our data. This is called a recipe. To create a recipe, you’ll first specify a formula for your model, indicating which variable is your outcome and which are your predictors. Using ~. here will indicate that we want to use all variables other than score as predictors. Then, we can specify a series of pre-processing steps for our data that directs our recipe to assign our variables a role or performs feature engineering steps. Pre-processing may be sound uncommon, but if you’ve ever used lm() (or several other R functions) you’ve done some of this by simply calling the function (e.g., automatic dummy-coding to handle categorical data). This is beneficial because it gives the analyst more control, despite adding complexity to the process.\nA complete list of possible pre-processing steps can be found here: https://recipes.tidymodels.org/articles/Custom_Steps.html\nrec \u0026lt;- recipe(score ~ ., train) %\u0026gt;% step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %\u0026gt;% # convert `test date` variable to a date update_role(contains(\u0026quot;id\u0026quot;), ncessch, new_role = \u0026quot;id vars\u0026quot;) %\u0026gt;% # declare ID variables step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %\u0026gt;% # remove variables with zero variances step_novel(all_nominal()) %\u0026gt;% # prepares test data to handle previously unseen factor levels step_unknown(all_nominal()) %\u0026gt;% # categorizes missing categorical data (NA\u0026#39;s) as `unknown` step_medianimpute(all_numeric(), -all_outcomes(), -has_role(\u0026quot;id vars\u0026quot;)) %\u0026gt;% # replaces missing numeric observations with the median step_dummy(all_nominal(), -has_role(\u0026quot;id vars\u0026quot;)) # dummy codes categorical variables  Create a model The last step before bringing in our data is to specify our model. This will call upon functions from the {parsnip} package, which standardizes language for specifying a multitude of statistical models. There are a few core elements that you will need to specify for each model\nThe type of model This indicates what type of model you choose to fit, each of which will be a different function. We’ll be focusing on decision tree methods using bag_tree(), random_forest(), and boost_tree(). A full list of models can be found here https://www.tidymodels.org/find/parsnip/\n The engine set_engine() calls the package to support the model you specified above.\n The mode set_mode() indicates the type of prediction you’d like to use in your model, you’ll choose between regression and classification. Since we are looking to predict student scores, which is a continuous predictor, we’ll be choosing regression.\n The arguments set_args() allows you to set values for various parameters for your model, each model type will have a specific set of parameters that can be altered. For these parameters, you can either set a particular value or you can use the tune function to search for the optimal value of each parameter. Tuning requires a few extra steps, so we will leave the default arguments for clarity. For more information on tuning check out https://tune.tidymodels.org/.\n  Create a workflow Up to this point we’ve been setting up a lot of individual elements and now it is time to combine them to create a cohesive framework, called a workflow, so we can run our desired models. First, we’ll use the workflow() command and then we’ll pull in the recipe and model we already created. The next section shows three examples of specifying models and creating a workflow for different decision tree methods.\n Model Examples Bagged trees A bagged tree approach creates multiple subsets of data from the training set which are randomly chosen with replacement. Each subset of data is used to train a given decision tree. In the end, we have an ensemble of different models. The predictions from all the different trees are averaged together, giving us a stronger prediction than one tree could independently.\nSpecify model set.seed(100) mod_bag \u0026lt;- bag_tree() %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) %\u0026gt;% set_engine(\u0026quot;rpart\u0026quot;, times = 10) # 10 bootstrap resamples  Create workflow wflow_bag \u0026lt;- workflow() %\u0026gt;% add_recipe(rec) %\u0026gt;% add_model(mod_bag)  Fit the model set.seed(100) plan(multisession) fit_bag \u0026lt;- fit_resamples( wflow_bag, cv, metrics = metric_set(rmse, rsq), control = control_resamples(verbose = TRUE, save_pred = TRUE, extract = function(x) extract_model(x)))  Visualize The plot below shows the root nodes from a bagged tree made of 100 trees (10 folds x 10 bootstrapped resamples). Root nodes are the 1st node in a decision tree, and they are determined by which variable best optimizes a loss function (e.g., minimizes mean square error [MSE] for continuous outcomes or Gini Index for categorical outcomes). Put roughly, the most common root nodes can be thought of as the most “important” predictors.\n  Random forest Random forest is similar to bagged tree methodology but goes one step further. In addition to taking random subsets of data, the model also draws a random selection of features. Instead of utilizing all features, the random subset of features allows more predictors to be eligible root nodes. This is particularly useful for handling high dimensionality data (e.g., have more variables than participants/cases).\nSpecify the model set.seed(100) mod_rf \u0026lt;-rand_forest() %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;, num.threads = parallel::detectCores(), importance = \u0026quot;permutation\u0026quot;, verbose = TRUE) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) %\u0026gt;% set_args(trees = 1000)  Create workflow wflow_rf \u0026lt;- workflow() %\u0026gt;% add_model(mod_rf) %\u0026gt;% add_recipe(rec)  Fit the model set.seed(100) plan(multisession) fit_rf \u0026lt;- fit_resamples( wflow_rf, cv, metrics = metric_set(rmse, rsq), control = control_resamples(verbose = TRUE, save_pred = TRUE, extract = function(x) x) )  Visualize The plot below shows the root nodes from a random forest with 1000 trees (specified using set_args(trees = 1000) in the parsnip model object).\n  Boosted trees Boosted trees, like bagged trees, are an ensemble model. Instead of applying successive models to resampled data and pooling estimates, boosted trees fit the next tree to the residuals (i.e., error term) of the prior tree. The goal is to minimize residual error through multiple trees, and is typically done with fairly “shallow” decision tree (i.e., 1-6 splits in each tree). Though each model is only slightly improving the error rate, the sequential use of many shallow trees makes computationally efficient (i.e. reduced run time) and highly accurate predictions.\nSpecify the model mod_boost \u0026lt;- boost_tree() %\u0026gt;% set_engine(\u0026quot;xgboost\u0026quot;, nthreads = parallel::detectCores()) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;)  Create workflow wflow_boost \u0026lt;- workflow() %\u0026gt;% add_recipe(rec) %\u0026gt;% add_model(mod_boost)  Fit the model set.seed(100) plan(multisession) fit_boost \u0026lt;- fit_resamples( wflow_boost, cv, metrics = metric_set(rmse, rsq), control = control_resamples(verbose = TRUE, save_pred = TRUE) )  Visualize One of the few downfalls of {tidymodels} is its (current) inability to plot these tree-based models. For the past two models, it was simpler to extract root nodes and plot them, but their interpretation (as we’re fitting to residuals instead of data sets) are not straightforward. For that reason, we don’t have any pretty plots here. Instead, we’ll skip to evaluating the metrics of all models.\n   Evaluate metrics After running these three models, it’s time to evaluate their performance. We can do this with tune::collect_metrics(). The table below shows the estimate of the out-of-sample performance for each of our 3 models.\ncollect_metrics(fit_bag) %\u0026gt;% bind_rows(collect_metrics(fit_rf)) %\u0026gt;% bind_rows(collect_metrics(fit_boost)) %\u0026gt;% filter(.metric == \u0026quot;rmse\u0026quot;) %\u0026gt;% mutate(model = c(\u0026quot;bag\u0026quot;, \u0026quot;rf\u0026quot;, \u0026quot;boost\u0026quot;)) %\u0026gt;% select(model, everything()) %\u0026gt;% knitr::kable()   model .metric .estimator mean n std_err    bag rmse standard 96.62424 10 2.609574  rf rmse standard 95.46510 10 3.184353  boost rmse standard 94.86529 10 2.978113    Here, we are faced with a common problem in the machine learning world: choosing between models that perform similarly. Whether we would prefer random forest, bagged trees, or boosted trees may also depend on computational efficiency (i.e., time) or other factors. In practice, tuning several hyperparameters may have made one model clearly preferable over the others, but in our case - relying on all defaults - we would probably have similar performance with both models on a new data set and would prefer random forest or boosted trees models for their efficiency.\n Out-of-sample performance The final step is to apply each trained model to our test data using last_fit().\n# bagged trees final_fit_bag \u0026lt;- last_fit( wflow_bag, split = split ) # random forest final_fit_rf \u0026lt;- last_fit( wflow_rf, split = split ) # boosted trees final_fit_boost \u0026lt;- last_fit( wflow_boost, split = split ) The table below shows the actual out-of-sample performance for each of our 3 models.\n# show performance on test data collect_metrics(final_fit_bag) %\u0026gt;% bind_rows(collect_metrics(final_fit_rf)) %\u0026gt;% bind_rows(collect_metrics(final_fit_boost)) %\u0026gt;% filter(.metric == \u0026quot;rmse\u0026quot;) %\u0026gt;% mutate(model = c(\u0026quot;bag\u0026quot;, \u0026quot;rf\u0026quot;, \u0026quot;boost\u0026quot;)) %\u0026gt;% select(model, everything()) %\u0026gt;% knitr::kable()   model .metric .estimator .estimate    bag rmse standard 96.19641  rf rmse standard 91.35844  boost rmse standard 90.72458    After applying our 3 trained models to the unseen test data, it looks like our boosted trees model is the winner since it has the lowest RMSE. In this example, we only used 1% of the data to train these models, which could make it difficult to meaningfully compare their performance. In practice, our random forest model actually results in the best out-of-sample prediction (RMSE = 84.08) when using all of the available data, which we did for the Kaggle competition.\n ","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593016070,"objectID":"41b5be0e054160df36224dd8a3bb40a6","permalink":"/post/tidymodels-decision-tree-learning-in-r/","publishdate":"2020-06-24T00:00:00Z","relpermalink":"/post/tidymodels-decision-tree-learning-in-r/","section":"post","summary":"Intro Tidyverse’s newest release has recently come together to form a cohesive suite of packages for modeling and machine learning, called {tidymodels}. The successor to Max Kuhn’s {caret} package, {tidymodels} allows for a tidy approach to your data from start to finish.","tags":[],"title":"Tidymodels: Decision Tree Learning in R","type":"post"},{"authors":null,"categories":null,"content":"The last decade has seen explosive growth of online social networks, which are now a pervasive part of everyday life for many people. As such, it is important to understand the relationship between social media and mental health. Previous research has documented a variety of relationships between psychological characteristics and online behaviors. For example, it has been found that positive and negative emotions are related to self-expression online. Additionally, personality traits are correlated with word use and patterns of “likes” in Facebook and with word use and network structure on Twitter.\nAlthough previous work in this area has been promising, social media studies to date often rely on outward facing behaviors such as public posts or “likes” which are subject to self-monitoring or a public persona. Instead, we will use Twitter friends (the accounts one chooses to follow) as a behavioral measure that is less publicly highlighted on the platform and therefore, less subject to self-monitoring. We will use this behavioral data, as well as, self-reports of personality and mental health characteristics to better understand the relationship between mental health and social media usage. Specifically, we will examine if current mental health predicts which Twitter accounts participants choose to follow. This research will help us better understand how mental health and personality shape people’s online experiences.\n","date":1588636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588636800,"objectID":"0df18ed0a2b1ea738e04b21ef5e9398d","permalink":"/my-project/twitter-mental-health/","publishdate":"2020-05-05T00:00:00Z","relpermalink":"/my-project/twitter-mental-health/","section":"my-project","summary":"Does mental health predict the Twitter friends we choose?","tags":["Online social networks"],"title":"Twitter and Mental Health","type":"my-project"},{"authors":null,"categories":null,"content":"The last decade has seen explosive growth of online social networks, which are now a pervasive part of everyday life for many people. As such, it is important to understand the relationship between social media and mental health. Previous research has documented a variety of relationships between psychological characteristics and online behaviors. For example, it has found that positive and negative emotions are related to self-expression online. Additionally, personality traits are correlated with word use and patterns of “likes” in Facebook and with word use and network structure on Twitter.\nAlthough previous work in this area has been promising, social media studies to date often rely on outward facing behaviors such as public posts or “likes” which are subject to self-monitoring or a public persona. Instead, we will use Twitter friends (the accounts one chooses to follow) as a behavioral measure that is less publicly highlighted on the platform and therefore, less subject to self-monitoring. We will use this behavioral data, as well as, self-reports of personality and mental health characteristics to better understand the relationship between mental health and social media usage. Specifically, we will examine if current mental health predicts which Twitter accounts participants choose to follow. This research will help us better understand how mental health and personality shape people’s online experiences.\n","date":1586044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586044800,"objectID":"d61f95c2b81e80af667bc49345bc31f0","permalink":"/my-project/t1d-twitter/","publishdate":"2020-04-05T00:00:00Z","relpermalink":"/my-project/t1d-twitter/","section":"my-project","summary":"How do chronic illness communities form networks online?","tags":["Online social networks","Health"],"title":"Type 1 Diabetes Twitter Communities","type":"my-project"},{"authors":["Bradley T. Hughes, Cory K. Costello, Joshua Pearman, Pooya Razavi, Cianna Bedford-Petersen, Rita M. Ludwig, \u0026 Sanjay Srivastava"],"categories":null,"content":"","date":1578182400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578182400,"objectID":"a415800123e9f68bdb5be7e3b2f8a21e","permalink":"/publication/big5ses-preprint/","publishdate":"2020-01-05T00:00:00Z","relpermalink":"/publication/big5ses-preprint/","section":"publication","summary":"We use the AIID dataset, a large online study, to address three basic questions about personality and SES.","tags":["Measurement Invariance"],"title":"Big Five Across Socioeconomic Status - Measurement Invariance, Relationships, and Age Trends","type":"publication"},{"authors":null,"categories":null,"content":"Previous research has established the principle that situations can affect the expression of personality, though it is not well-understood what specific patterns characterize this change across situations. Here, we explore the possibility of fault lines in personality. A fault line implies that there is a change in personality expression initiated by a transition between two distinct types of situations. 474 University of Oregon undergraduate students completed a questionnaire in which 15 personality tendencies were juxtaposed with each of 41 differing situations. Our findings replicated previous research indicating that Honesty/Propriety yields the least variance between situations while Emotional Stability and Extraversion yield the most variance.\nPrincipal components analysis was used to examine cross-situational inconsistency with four models already present in psychological literature, each implying a distinct fault line. We found that our models of threat vs reward, positive affect vs negative affect, and agency vs no agency were clear sources of cross-situational inconsistency.\n","date":1571961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571961600,"objectID":"a48896eb28f247b189c06b188e96f45b","permalink":"/my-project/personality-and-situations/","publishdate":"2019-10-25T00:00:00Z","relpermalink":"/my-project/personality-and-situations/","section":"my-project","summary":"What influences personality to change across situtaions?","tags":["Personality"],"title":"Personality Across Situations","type":"my-project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"Hello!","tags":null,"title":"Landing Page","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"Hello!","tags":null,"title":"New Projects Page","type":"widget_page"},{"authors":["Cianna Bedford-Petersen, Colin G. DeYoung, Valerie Tiberius, \u0026 Moin Syed"],"categories":null,"content":"","date":1526515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526515200,"objectID":"450793b4c2cea9de74fdd4015996a5f2","permalink":"/publication/virtue/","publishdate":"2020-01-05T00:00:00Z","relpermalink":"/publication/virtue/","section":"publication","summary":"We demonstrate in a longitudinal sample that success in current personal projects predicts various forms of subjective well-being, even when controlling for past levels of well-being and project success.","tags":["Well-being","Longitudinal"],"title":"Integrating philosophical and psychological approaches to well-being - The role of success in personal projects","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"94d1972c7a695ba369190c1d959e48c9","permalink":"/my-project/social-media-attitudes/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/my-project/social-media-attitudes/","section":"my-project","summary":"Step-by-step visualizations of data from the PEW Research Center","tags":["Demo"],"title":"Social Media Habits","type":"my-project"}]